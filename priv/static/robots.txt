# See https://www.robotstxt.org/robotstxt.html for documentation on how to use the robots.txt file

# Allow all search engines to crawl the site
User-agent: *
Allow: /

# Disallow development and admin routes
Disallow: /dev/
Disallow: /api/

# RSS Feed
Allow: /feed.xml

# Sitemap location
Sitemap: https://droo.foo/sitemap.xml
